import streamlit as st
import requests
import json
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="RAG arXiv Generator",
    page_icon="üìö",
    layout="wide"
)

# URL de l'API
API_URL = "http://localhost:8000"

# Titre principal
st.title("üìö arXiv Research Assistant")
st.markdown("Recherchez et g√©n√©rez du contenu bas√© sur les derniers articles arXiv")

# Sidebar pour les options
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Choix du mode
    mode = st.radio(
        "Mode de recherche",
        ["üî¨ arXiv (auto)", "üìÑ Document upload√©"],
        help="arXiv t√©l√©charge automatiquement les papers, Document utilise vos fichiers"
    )
    
    st.divider()
    
    # Statistiques (optionnel)
    st.header("üìä Statistiques")
    if st.button("üîÑ Rafra√Æchir stats"):
        try:
            response = requests.get(f"{API_URL}/debug/chunks")
            if response.status_code == 200:
                data = response.json()
                st.metric("Documents index√©s", data.get("total", 0))
        except:
            st.warning("API non accessible")

# Zone principale
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üí¨ Votre question")
    
    # Input pour la question
    user_query = st.text_area(
        "Posez votre question de recherche",
        placeholder="Ex: What are the main architectures used in multimodal large language models?",
        height=100
    )
    
    # Options avanc√©es (collapsible)
    with st.expander("üîß Options avanc√©es"):
        show_chunks = st.checkbox("Afficher les chunks r√©cup√©r√©s", value=True)
        show_metadata = st.checkbox("Afficher les m√©tadonn√©es compl√®tes", value=False)

with col2:
    st.header("üéØ Actions")
    
    # Upload de document (si mode Document)
    if mode == "üìÑ Document upload√©":
        uploaded_file = st.file_uploader(
            "Uploader un PDF",
            type=["pdf"],
            help="Le document sera index√© avant la recherche"
        )
        
        if uploaded_file and st.button("üì§ Ing√©rer le document"):
            with st.spinner("Ingestion en cours..."):
                files = {"file": uploaded_file}
                response = requests.post(f"{API_URL}/ingest", files=files)
                
                if response.status_code == 200:
                    data = response.json()
                    st.success(f"‚úÖ Document ing√©r√© ! ID: {data['doc_id']}")
                    st.session_state['last_doc_id'] = data['doc_id']
                else:
                    st.error("‚ùå Erreur lors de l'ingestion")

# Bouton de g√©n√©ration
if st.button("üöÄ G√©n√©rer la r√©ponse", type="primary", use_container_width=True):
    if not user_query.strip():
        st.warning("‚ö†Ô∏è Veuillez entrer une question")
    else:
        # D√©terminer l'endpoint
        if mode == "üî¨ arXiv (auto)":
            endpoint = f"{API_URL}/arxiv/generate"
            payload = {"prompt": user_query}
        else:
            endpoint = f"{API_URL}/generate"
            doc_id = st.session_state.get('last_doc_id')
            payload = {
                "prompt": user_query,
                "document": doc_id if doc_id else None
            }
        
        # Appel API avec spinner
        with st.spinner("üîç Recherche en cours... (cela peut prendre 10-30 secondes pour arXiv)"):
            try:
                response = requests.post(endpoint, json=payload, timeout=60)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Affichage de la r√©ponse g√©n√©r√©e
                    st.success("‚úÖ R√©ponse g√©n√©r√©e avec succ√®s !")
                    
                    # Onglets pour organiser l'affichage
                    tab1, tab2, tab3 = st.tabs(["üìù R√©ponse", "üìö Sources", "üîç D√©tails"])
                    
                    with tab1:
                        st.markdown("### R√©ponse")
                        st.markdown(data.get("generated_text", "Aucune r√©ponse g√©n√©r√©e"))
                    
                    with tab2:
                        st.markdown("### Sources cit√©es")
                        sources = data.get("sources", [])
                        
                        if sources:
                            for i, source in enumerate(sources, 1):
                                with st.expander(f"üìÑ Source {i}: {source.get('title', source.get('source', 'N/A'))}"):
                                    col_a, col_b = st.columns(2)
                                    
                                    with col_a:
                                        st.write("**Fichier:**", source.get('source', 'N/A'))
                                        st.write("**Page:**", source.get('page', 'N/A'))
                                        st.write("**Doc ID:**", source.get('doc_id', 'N/A'))
                                    
                                    with col_b:
                                        if source.get('authors'):
                                            authors = source['authors'].split(' | ')
                                            st.write("**Auteurs:**", ", ".join(authors[:3]) + (" et al." if len(authors) > 3 else ""))
                                        if source.get('published'):
                                            date = source['published'][:10]
                                            st.write("**Publi√©:**", date)
                        else:
                            st.info("Aucune source disponible (mode LLM pur)")
                    
                    with tab3:
                        if show_chunks and data.get("retrieved_chunks"):
                            st.markdown("### Chunks r√©cup√©r√©s")
                            
                            for i, chunk in enumerate(data["retrieved_chunks"], 1):
                                with st.expander(f"Chunk {i} - Score: {chunk.get('score', 0):.4f}"):
                                    st.text_area(
                                        "Contenu",
                                        chunk.get("text", ""),
                                        height=150,
                                        key=f"chunk_{i}"
                                    )
                                    
                                    if show_metadata:
                                        st.json(chunk.get("metadata", {}))
                        else:
                            st.info("Aucun chunk r√©cup√©r√© ou option d√©sactiv√©e")
                        
                        # JSON brut
                        with st.expander("üìã R√©ponse JSON compl√®te"):
                            st.json(data)
                
                else:
                    st.error(f"‚ùå Erreur API: {response.status_code}")
                    st.code(response.text)
            
            except requests.exceptions.Timeout:
                st.error("‚è±Ô∏è Timeout: La requ√™te a pris trop de temps")
            except requests.exceptions.ConnectionError:
                st.error("üîå Erreur de connexion: V√©rifiez que l'API tourne sur http://localhost:8000")
            except Exception as e:
                st.error(f"‚ùå Erreur: {str(e)}")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>ü§ñ Powered by FastAPI + ChromaDB + OpenAI | üìö arXiv API</p>
</div>
""", unsafe_allow_html=True)